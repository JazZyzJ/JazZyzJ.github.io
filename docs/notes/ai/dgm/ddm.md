# Discrete Diffusion Models

!!! abstract

    ä¼ ç»Ÿçš„Continuous Diffusion Modelså¯ä»¥å¤„ç†è¿ç»­çš„æ•°å€¼æ•°å€¼ï¼Œä½†æ˜¯åœ¨å®é™…é—®é¢˜ä¸­ï¼Œå…¶å®æœ‰å¾ˆå¤šæ•°æ®çš„ç‰¹å¾å¹¶ä¸è¿ç»­ï¼Œæ¯”å¦‚æ–‡å­—æœ¬èº«ã€DNAã€è›‹ç™½è´¨åºåˆ—ã€åŸå­ç±»å‹ç­‰ï¼Œå¦‚ä½•å¤„ç†è¿™ç±»çš„æ•°æ®ä¹Ÿæ˜¯éœ€è¦è€ƒè™‘çš„é—®é¢˜ã€‚

    <div align="center">
        <img src="/../../../../assets/pics/ai/dgm/ddm/ddm1.png" style="width: 100%;">
    </div>

## Intro 

æˆ‘ä»¬å¾ˆå®¹æ˜“å»æƒ³ï¼Œä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥ä½¿ç”¨å…ˆå‰æåˆ°çš„é‚£äº›æ¨¡å‹ï¼Œå°†æ•°æ®åˆ†å¸ƒç¦»æ•£åŒ–ç„¶åç›´æ¥é‡‡æ ·å‘¢ï¼Ÿæœ‰ä»¥ä¸‹å‡ æ–¹é¢çš„é—®é¢˜éœ€è¦è€ƒè™‘ï¼š

- é‡‡æ ·

<div align="center">
    <img src="/../../../../assets/pics/ai/dgm/ddm/ddm2.png" style="width: 100%;">
</div>

å¯ä»¥çœ‹åˆ°åœ¨è¿ç»­ç©ºé—´å†…çš„é‡‡æ ·ï¼Œæˆ–è€…è¯´åœ¨å›¾åƒé—®é¢˜ä¸Šï¼Œæˆ‘ä»¬æ˜¯ç¦»æ•£çš„æ•°æ®ï¼Œä½†æ˜¯å¯ä»¥è¿‘ä¼¼å–ç»“æœçš„æƒ…å†µä¸‹ï¼Œè¿™ä¸ªé—®é¢˜è¿˜æ¯”è¾ƒå¥½è§£å†³ï¼Œä½†æ˜¯å¯¹äºéå›¾åƒçš„æ•°æ®ï¼Œæˆ‘ä»¬ä¸€æ—¦é‡‡æ ·åˆ°è¿œç¦»ç‰¹å®šæ•°æ®ç‚¹çš„ä½ç½®ï¼Œå°±å˜å¾—ä¸å¥½å¤„ç†äº†ã€‚åŒæ—¶ï¼Œåƒæ–‡æœ¬ä¿¡æ¯è¿™ç§é—®é¢˜ï¼Œè¿‘ä¼¼å–å€¼åœ¨é«˜ç»´ç©ºé—´å¹¶ä¸å…·å¤‡å¯è§£é‡Šæ€§ã€‚

- è®­ç»ƒ

ç¦»æ•£ä¿¡æ¯æ˜¯ä¸èƒ½è¢«ç›´æ¥åå‘ä¼ æ’­çš„ï¼Œä¹Ÿå°±æ„å‘³ç€æˆ‘ä»¬æ— æ³•ç›´æ¥æ›´æ–°æ¨¡å‹å‚æ•°

---

ç°åœ¨çš„åœ¨å¤„ç†æ–‡æœ¬ç±»ä¿¡æ¯çš„æ–¹æ³•å°±æ˜¯ARæ–¹æ³•ï¼Œæˆ‘ä»¬ç”¨é“¾å¼æ³•åˆ™è¿›è¡Œæ¦‚ç‡è®¡ç®—ç„¶åé€ä¸ªinferenceï¼Œä½†æ˜¯ARæœ‰ç€æˆ‘ä»¬éƒ½çŸ¥é“çš„ä¸è¶³ä¹‹å¤„ï¼š

- **Sampling "drifts"** - Yann LeCun

    æ¨¡å‹çš„é”™è¯¯æ˜¯ä¼šè¢«ä¸æ–­ç§¯ç´¯çš„

- **No resaonable bias for non-language tasks**

    åœ¨è¯­è¨€ä¸­ï¼Œä»å·¦å‘å³æ˜¯åˆç†çš„ï¼Œä½†æ˜¯å…¶ä»–çš„å‘¢ï¼Ÿ


- **Slow sampling due to iterative nature**



Ok, let's take a look at what we can do with discrete datağŸ¤“



## Modeling

### Score matching on discrete spaces

åœ¨è¿™é‡Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ª **Concrete Score** ä¸ä¹‹å‰çš„scoreåšåŒºåˆ†ï¼Œå…ˆå®šä¹‰ä¸€ä¸ªæ–°çš„æ¢¯åº¦

$$
\nabla f(x) \equiv [f(y) - f(x)]_{y \text{ neighbor of } x}
$$

ç„¶åé‡å†™æˆ‘ä»¬çš„scoreï¼š

$$
\nabla_x \log p = \frac{\nabla p(x)}{p(x)} = [\frac{p(y)}{p(x)}]_y -1 
$$

!!! bug "Strict define on neighbor"

    ä½†æ˜¯è¿™é‡Œæ˜¯æœ‰ç‚¹é—®é¢˜çš„ï¼šå¯ä»¥çœ‹åˆ°å› ä¸ºæˆ‘ä»¬çš„å®šä¹‰æ˜¯å¯¹yçš„æ‰€æœ‰é‚»å±…xéƒ½è¿›è¡Œè®¡ç®—ï¼Œæ‰€ä»¥å¤æ‚åº¦å¯ä»¥è½»æ¾åˆ°è¾¾$O(N^{2d})$ï¼Œæˆ‘ä»¬é‡‡å–ä¸€ä¸ªæ›´localçš„æ–¹å¼ï¼Œå¯¹ä¸€ä¸ªåºåˆ—çš„æ¦‚ç‡$p(x_1, x_2, \cdots, x_n)$ï¼Œæˆ‘ä»¬åªæ¯”è¾ƒç›¸åŒä½ç½®çš„å€¼ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼š

    yæ˜¯xçš„é‚»å±…ï¼Œå½“ä¸”ä»…å½“yä¸xåªæœ‰ä¸€ä¸ªåˆ†é‡çš„ä¸åŒ 

    $$
    \frac{p(x_1, \cdots, \hat{x_i}, \cdots, x_d)}{p(x_1, \cdots, x_i, \cdots, x_d)}
    $$

    which is $O(Nd)$


é€šè¿‡ä¸€ä¸ªseq-to-seqç½‘ç»œå¤„ç†è¿‡åæˆ‘ä»¬å°±æœ‰äº†ä¸€ä¸ªå¯ä»¥æ„ŸçŸ¥ä¸Šä¸‹æ–‡çš„BERT-like but non-autoregressive model

<div align="center">
    <img src="/../../../../assets/pics/ai/dgm/ddm/ddm3.png" style="width: 70%;">
</div>



ç°åœ¨æˆ‘ä»¬çš„ç›®æ ‡å°±æ˜¯å¦‚ä½•å­¦ä¹ ä¸€ä¸ªscoreï¼š$s_\theta(x)$ s.t. $s_\theta(x)_y \approx \frac{p(y)}{p(x)}$

!!! definition "Score Entropy"

    é¦–å…ˆå†™å‡ºä¸€ä¸ªåŸå§‹çš„æœŸæœ›è¡¨è¾¾å¼ï¼Œæ˜¯ä¸€ä¸ªç±»ä¼¼äºEntropyçš„è®¡ç®—æ–¹å¼ï¼š

    $$\begin{aligned}\min_\theta\mathbb{E}_{x\thicksim p}\sum_{y\neq x}s_\theta(x)_y-\frac{p(y)}{p(x)}\log s_\theta(x)_y\end{aligned}$$ 

    è¿™é‡Œéœ€è¦æ³¨æ„ä¸¤ä¸ªç‚¹ï¼Œå¯¹äºç›®æ ‡å‡½æ•°çš„è®¾ç½®æ»¡è¶³be principledï¼š

    - no negative values
    - recover true values

    ç¬¬ä¸€ç‚¹æ˜¯åœ¨è®¾è®¡æ—¶å°†åˆ†æ•°æ”¾åœ¨logä¸­ï¼Œä¿è¯ä¸€å®šä¸ºæ­£ï¼›ç¬¬äºŒç‚¹æ˜¯ä¸Šé¢å¼å­çš„å¯¼æ•°ä¸º0çš„ç‚¹ï¼Œæ°å¥½å°±æ˜¯é¢„æµ‹å€¼ç­‰äºçœŸå®å€¼çš„ç‚¹



ç„¶åå°±æ˜¯æŒ‰ç…§ä¹‹å‰çš„æ€è·¯ï¼Œæˆ‘ä»¬æƒ³åŠæ³•å¯¹è¿™ä¸ªIntractableçš„é¡¹è¿›è¡Œè¿‘ä¼¼ï¼Œè¿™é‡Œé—®é¢˜é›†ä¸­åœ¨ä¸¤ä¸ªæ¦‚ç‡çš„æ¯”å€¼ä¸Šï¼Œæˆ‘ä»¬çœ‹çœ‹æœ‰ä»€ä¹ˆæ–¹æ³•å¯ä»¥åšè¿‘ä¼¼

è¿™é‡Œé‡‡ç”¨çš„æ–¹å¼æ˜¯**Denoising Score Entropy**ï¼Œä¹Ÿå°±æ˜¯æ¨¡ä»¿denoising score matchingçš„æ–¹å¼

!!! note "Denoising Score Matching"

    Assume $p(x) = \sum_{x_0} p(x|x_0)p_0(x_0)$, which means: $p(x)$ is a convolution of some base distribution $p_0$ and some kernel $p$

    then we rewrite:

    <div align="center">
        <img src="/../../../../assets/pics/ai/dgm/ddm/ddm4.png" style="width: 100%;">
    </div>

    ä»£å›åŸå¼ï¼š

    <div align="center">
        <img src="/../../../../assets/pics/ai/dgm/ddm/ddm5.png" style="width: 100%;">
    </div>


### Sampling using the concrete score

> ç°åœ¨æˆ‘ä»¬æ¥çœ‹å¦‚æœå…·ä½“åšé‡‡æ ·

#### Continuous Time Markov Chain


æˆ‘ä»¬çš„æ“ä½œå¯¹è±¡$p_t \in \mathbb{R}^{|\mathcal{X}|}$ï¼Œæ˜¯ä¸€ä¸ªå¾ˆå¤§å¾ˆå¤§çš„å‘é‡ã€‚forwardè¿‡ç¨‹ç”¨ä¸€ä¸ªODEå®šä¹‰ï¼š

!!! definition "Forward Process"
    $$
    dp_t = Q_t p_t
    $$

    è½¬ç§»çŸ©é˜µ$Q_t$éœ€è¦æ»¡è¶³å¦‚ä¸‹å®šä¹‰ï¼š

    - Columns sum to 0
    - Non-diagonal elements are $\geq 0$

    å› ä¸º$Q_t$æ˜¯éšæ—¶é—´å˜åŒ–çš„ï¼Œæˆ‘ä»¬æŠŠæ—¶é—´å‚æ•°å•ç‹¬æ‹¿å‡ºæ¥ï¼š
    
    $$Q_t = \sigma(t) Q$$

    è¿™é‡Œçš„$\sigma(t)$æ˜¯ä¸€ä¸ªéšæ—¶é—´å˜åŒ–çš„å‡½æ•°ï¼Œç”¨äºæ§åˆ¶å™ªå£°çš„å¼ºåº¦

    !!! example "Choice of $Q$"

        æˆ‘ä»¬æœ‰ä¸¤ç§æ–¹å¼æ¥å¯¹æ•°æ®è¿›è¡Œperturbï¼š

        - Random

            $$Q^\mathrm{uniform}=\begin{bmatrix}1-N&1&\cdots&1\\1&1-N&\cdots&1\\\vdots&\vdots&\ddots&\vdots\\1&1&\cdots&1-N\end{bmatrix}$$

        - Mask

            $$Q^{\mathrm{absorb}}=\begin{bmatrix}-1&0&\cdots&0&0\\0&-1&\cdots&0&0\\\vdots&\vdots&\ddots&\vdots&\vdots\\0&0&\cdots&-1&0\\1&1&\cdots&1&0\end{bmatrix}$$


$Q_t$ æ§åˆ¶ç€æˆ‘ä»¬çš„çŠ¶æ€è½¬ç§»ï¼š

$$p(x_{t+\Delta t}=j|x_t=i)=\delta_{i,j}+Q_t(j,i)\Delta t+O(\Delta t^2)$$

å…¶ä¸­$\delta_{i,j}$æ˜¯Kronecker delta functionï¼Œç”¨äºåˆ¤æ–­æˆ‘ä»¬å½“å‰çš„ä½ç½®ï¼Œç„¶åç”¨$Q_t(j,i)\Delta t$è¡¨ç¤ºæˆ‘ä»¬ä»ä¸€ä¸ªä½ç½®è½¬ç§»åˆ°å¦ä¸€ä¸ªä½ç½®çš„æ¦‚ç‡

è¿™æ—¶æˆ‘ä»¬çš„æ¦‚ç‡è½¬ç§»å°±æ˜¯ï¼š


$$\begin{aligned}p(x_t=j|x_0=i)=\exp(\Sigma(t)Q)(j,i)\end{aligned}$$

å…¶ä¸­$\Sigma(t) = \int_0^t \sigma(s) ds$è¡¨ç¤ºå™ªå£°çš„ç´¯ç§¯é‡ã€‚è¿™ä¸ªå¼å­å°±æ˜¯å…ˆå‰ODEçš„ç²¾ç¡®è§£ï¼Œè¡¨ç¤ºä»iåˆ°jçš„æ¦‚ç‡


åŒæ—¶å¯¹äºæˆ‘ä»¬çš„å¤„ç†æ–¹å¼ä¸Šï¼Œå¦‚æœç›´æ¥å¯¹ä¸¤ä¸ªseqè¿›è¡Œè½¬ç§»å¼€é”€éå¸¸å¤§ï¼Œæ‰€ä»¥è¿˜æ˜¯é‡‡ç”¨ä¹‹å‰æåˆ°çš„localæ–¹å¼ï¼Œå¯¹tokenè¿›è¡Œç´¯åŠ ï¼š

$$p_{t|0}^\mathrm{seq}(\widehat{\mathbf{x}}|\mathbf{x})=\prod_{i=1}^dp_{t|0}^\mathrm{tok}(\widehat{x}^i|x^i)$$




----------


ç°åœ¨æ¥çœ‹ä¸€ä¸‹reverse process

!!! definition "Reverse Process"

    $$dp_{T-t}=\overline{Q}_{T-t}p_{T-t}$$

    å…¶ä¸­ï¼š

    $$\bar{Q_t}(y, x) = \begin{cases}s_\theta(x,t)_yQ_t(x,y)&x\neq y\\{-}\sum_{z\neq x}\overline{Q}_t^\theta(z,y)&x=y&\end{cases}$$

> äº‹å®ä¸ŠCS236è®²åˆ°è¿™å°±ç»“æŸäº†ï¼ŒAaronåœ¨è¯¾å ‚ä¸Šå¹¶æ²¡æœ‰å®Œå…¨å±•å¼€ï¼Œæˆ‘åœ¨åé¢ç›´æ¥çœ‹äº†åŸè®ºæ–‡[Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution](https://arxiv.org/abs/2310.16834)


### Likelihood training 

ç›´æ¥ç»™å‡ºï¼š

$$-\log p_0^\theta(x_0)\leq\mathcal{L}_{\mathrm{DWDSE}}(x_0)+D_{KL}(p_{T|0}(\cdot|x_0)\parallel p_{\mathrm{base}})$$

å…¶ä¸­$mathcal{L}_{\mathrm{DWDSE}}$æ˜¯ diffusion weighted denoising score entropyå¯¹$x_0$çš„loss

ä»–çš„è¡¨è¾¾å¼éå¸¸é•¿...

$$\int_0^T\mathbb{E}_{x_t\thicksim p_{t|0}(\cdot|x_0)}\sum_{y\neq x_t}Q_t(x_t,y)\left(s_\theta(x_t,t)_y-\frac{p_{t|0}(y|x_0)}{p_{t|0}(x_t|x_0)}\log s_\theta(x_t,t)_y+K\left(\frac{p_{t|0}(y|x_0)}{p_{t|0}(x_t|x_0)}\right)\right)dt$$

ä½†å…¶å®æ ¸å¿ƒéƒ¨åˆ†è¿˜æ˜¯ä¹‹å‰æåˆ°çš„ï¼Œåé¢çš„Kæ˜¯normalizing constantç”¨äºä¿è¯Lå¤§äº0


### Tweedie $\tau$ leaping

å¦‚æœæŒ‰ç…§å…ˆå‰çš„è®¾å®šODEï¼Œæˆ‘ä»¬å¯ä»¥ç»™å‡ºdenoiser:

$$p_{0|t}(x_0|x_t)=\left(\exp(-tQ)\left[\frac{p_t(i))}{p_t(x_t)}\right]_{i=1}^N\right)_{x_0}\exp(tQ)(x_t,x_0)$$

ä½†é—®é¢˜æ˜¯æˆ‘ä»¬ä¸èƒ½ç»™å‡ºæ‰€æœ‰çš„ratioï¼ˆè®ºæ–‡ä¸­è¯´åªèƒ½ç»™å‡ºHammingè·ç¦»ä¸º1çš„ï¼‰ï¼Œä½†æ˜¯æˆ‘ä»¬ä¹‹å‰æœ‰è®¾å®šè¿‡$Q$ä½œä¸ºä¸­è½¬ç«™ï¼Œæ­¤æ—¶æˆ‘ä»¬ä¸åœ¨è¯•å›¾ä¸€æ­¥ç›´æ¥è·³åˆ°ç»“æœï¼Œè€Œæ˜¯é‡‡ç”¨ä¸€ä¸ªæ›´å°çš„ã€ç¦»æ•£çš„æ—¶é—´æ­¥é•¿$\Delta t$ï¼ŒåŒæ—¶ç”±äºæœ‰$\tau$-leaping independence conditionï¼Œæˆ‘ä»¬å‡è®¾å’‹åœ¨è¿™ä¸ªæ—¶é—´æ®µå†…åºåˆ—ä¸­çš„æ¯ä¸ªtokenæ˜¯ç‹¬ç«‹denoiseçš„ï¼Œæ­¤æ—¶çš„è½¬ç§»æ¦‚ç‡ï¼š

$$p^{\mathrm{tweedie}}(x_{t-\Delta t}^i|x_t) = \left(\exp(-\sigma_t^{\Delta t}Q)\mathbf{s}_\theta(\mathbf{x_t},\mathbf{t})_i\right)_{x_{t-\Delta t}^i}\cdot\exp(\sigma_t^{\Delta t}Q)(x_t^i,x_{t-\Delta t}^i)$$

where $\sigma_t^{\Delta t}=(\overline{\sigma}(t)-\overline{\sigma}(t-\Delta t))$



æœ€ç»ˆå¾—åˆ°çš„ç®—æ³•ï¼š

<div align="center">
    <img src="/../../../../assets/pics/ai/dgm/ddm/ddm6.png" style="width: 100%;">
</div>

<div align="center">
    <img src="/../../../../assets/pics/ai/dgm/ddm/ddm7.png" style="width: 100%;">
</div>





